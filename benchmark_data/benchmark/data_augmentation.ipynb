{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adba3bf3-41c8-47f6-aff8-569318bb810a",
   "metadata": {},
   "source": [
    "# Design a bigger dataset of queries by using data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc3642-39cb-46ef-b6bd-922190908617",
   "metadata": {},
   "source": [
    "We want to change two things:\n",
    "*  we change some filter conditions \n",
    "*  we (exhaustively) change the attribute in the MIN-aggregation, such that for each query one variable of each relation is represented once in the new dataset\n",
    "\n",
    "Dataset size in the beginning: 229\n",
    "*  STATS: 146\n",
    "*  SNAP: 40\n",
    "*  JOB: 15\n",
    "*  LSQB: 2\n",
    "*  HETIO: 26\n",
    "\n",
    "#### Augmentation: Filter (+ changing connections for HETIO)\n",
    "By hand we change each STATS and JOB query twice with changing different filters. (SNAP and LSQB do not have any filters.)   \n",
    "(The new queries are called \"query\"-augF1 and \"query\"-augF2, where \"query\" is the original name of the query.)   \n",
    "For 6 STATS queries there is only one filter. Then we only create one new query \"query\"-augF1. This is the case for:\n",
    "*  STATS: 024-017\n",
    "*  STATS: 025-001\n",
    "*  STATS: 096-095\n",
    "*  STATS: 100-005\n",
    "*  STATS: 111-056\n",
    "*  STATS: 143-126\n",
    "In the most cases we change the values of $>, <, \\geq, \\leq$ conditions.\n",
    "In some cases we also change the equality conditions and we got the new string values like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565d2ccd-b150-49f7-8e2b-bc764b0837ec",
   "metadata": {},
   "source": [
    "![Example Image](images/imdb_random_keyword.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50c8fe-9d59-4445-893a-eebea0f6cabb",
   "metadata": {},
   "source": [
    "For the HETIO dataset we create 12 new queries, where we have 4 queries with filters (queries 5-8). Here we again change the filters two times.  \n",
    "For the other 8 queries we do augmentation in a way that we replace one connection in the graph with another one between the same two nodes.   \n",
    "(e.g. we replace upregulates with downregulates between disease and gene) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f685d0-5c2a-473d-8d2c-f3a2f90cab2b",
   "metadata": {},
   "source": [
    "![Example Image2](images/hetio_graph.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b56aefc-ca0f-4faf-a545-0145df081fd4",
   "metadata": {},
   "source": [
    "We get multiple variants for those 8 queries:\n",
    "*  2 variants for queries: 12, 13\n",
    "*  3 variants for queries: 10, 11, 14, 16\n",
    "*  9 variants for queries: 9, 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f215859-ec33-4f47-8a88-f21c89191cc7",
   "metadata": {},
   "source": [
    "Therefore we get a new dataset with size: 591\n",
    "*  STATS: 140 * 3 + 6 * 2 = 432\n",
    "*  SNAP: 40\n",
    "*  JOB: 15 * 3 = 45\n",
    "*  LSQB: 2\n",
    "*  HETIO: 26 (not changed) + 4 * 3 (filter) + 2 * 2 + 4 * 3 + 2 * 9 = 72"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac043533-85a0-4952-b324-502b2a5c5e4f",
   "metadata": {},
   "source": [
    "#### Augmentation: Change aggregate-attribute\n",
    "Now we take this new dataset and change the attribute in the MIN such that for each relation per query there is a query with an attribute of this table in the aggregation. The new dataset size is now the sum of the number of relations per query.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4612970-1936-4327-b09a-d6c050201b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATS: 1876\n",
      "SNAP: 244\n",
      "JOB: 264\n",
      "LSQB: 14\n",
      "HETIO: 538\n",
      "This gives us 2936 queries in total\n"
     ]
    }
   ],
   "source": [
    "# get the number of queries, which we get after this augmentation\n",
    "import re\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = 'scala_commands_augment_filter.txt'\n",
    "\n",
    "queries_stats = 0\n",
    "queries_snap = 0\n",
    "queries_job = 0\n",
    "queries_lsqb = 0\n",
    "queries_hetio = 0\n",
    "\n",
    "# Open input and output files\n",
    "with open(input_file, 'r') as f_input:\n",
    "    # Read input file line by line\n",
    "    for line in f_input:\n",
    "        # Split each line into components\n",
    "        pattern = r'(?<!\\\\)\\\"|\\\"(?<!\\\\)(?=\\s+\\\"|$)'\n",
    "        components = re.split(pattern, line)\n",
    "        \n",
    "        # Extract relevant information\n",
    "        benchmark = components[3]\n",
    "        number = components[5]\n",
    "        query = components[1].strip()\n",
    "\n",
    "        query_upper = query.upper()\n",
    "        from_index = query_upper.find(\"FROM\")\n",
    "        where_index = query_upper.find(\"WHERE\")\n",
    "        number_of_relations = query[from_index:where_index].count(\",\") + 1\n",
    "\n",
    "        if benchmark == \"STATS\":\n",
    "            queries_stats += number_of_relations\n",
    "        elif benchmark == \"SNAP\":\n",
    "            queries_snap += number_of_relations\n",
    "        elif benchmark == \"JOB\":\n",
    "            queries_job += number_of_relations\n",
    "        elif benchmark == \"LSQB\":\n",
    "            queries_lsqb += number_of_relations\n",
    "        elif benchmark == \"HETIO\":\n",
    "            queries_hetio += number_of_relations\n",
    "        else:\n",
    "            print(\"other benchmark?\")\n",
    "\n",
    "print(\"STATS:\", queries_stats)\n",
    "print(\"SNAP:\", queries_snap)\n",
    "print(\"JOB:\", queries_job)\n",
    "print(\"LSQB:\", queries_lsqb)\n",
    "print(\"HETIO:\", queries_hetio)\n",
    "print(\"This gives us\", queries_stats + queries_snap + queries_job + queries_lsqb + queries_hetio, \"queries in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339e5fc4-773e-4203-8e18-5326678ac4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.10/dist-packages (2.9.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a291f49-9463-4702-ad40-f8383a12e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33063732-cb7d-40a1-9646-758b72144747",
   "metadata": {},
   "source": [
    "Do the augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2efd323-55ab-4bb7-87a3-836d4916e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output file paths\n",
    "input_file = 'scala_commands_augment_filter.txt'\n",
    "output_file = 'scala_commands_augment_filter_agg.txt'\n",
    "\n",
    "# Open input and output files\n",
    "with open(input_file, 'r') as f_input, open(output_file, 'w', newline='') as f_output:\n",
    "    \n",
    "    # Read input file line by line\n",
    "    for line in f_input:\n",
    "        # Split each line into components\n",
    "        pattern = r'(?<!\\\\)\\\"|\\\"(?<!\\\\)(?=\\s+\\\"|$)'\n",
    "        components = re.split(pattern, line)\n",
    "        \n",
    "        benchmark = components[3]\n",
    "        number = components[5]\n",
    "        query = components[1].strip()\n",
    "        \n",
    "        query_upper = query.upper()\n",
    "        from_index = query_upper.find(\"FROM\")\n",
    "        where_index = query_upper.find(\"WHERE\")\n",
    "        relations_list = query[from_index+4:where_index].split(\",\")\n",
    "        relations = {relation.strip().rsplit(maxsplit=1)[-1]: relation.strip().split(maxsplit=1)[0] for relation in relations_list}\n",
    "\n",
    "        # get all relations occuring in the query and their aliases\n",
    "        min_index = query_upper.find(\"MIN\")\n",
    "        agg = query[min_index+4:from_index-2].strip().split(\".\")[0].strip()\n",
    "        relations = {key: value for key, value in relations.items() if key != agg}\n",
    "    \n",
    "        if benchmark == \"JOB\":\n",
    "            database = \"imdb\"\n",
    "        else:\n",
    "            database = benchmark.lower()\n",
    "        conn = psycopg2.connect(\n",
    "            host=\"postgres\",\n",
    "            database=database,\n",
    "            user=database,\n",
    "            password=database\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # get one column name for each relation\n",
    "        new_aggs = []\n",
    "        for key, value in relations.items():\n",
    "            query_col = f\"\"\"SELECT column_name FROM information_schema.columns WHERE table_name = '{value.lower()}'\"\"\"\n",
    "            cur.execute(query_col)\n",
    "            row = cur.fetchone()[0]\n",
    "            new_aggs.append(key + \".\" + row)\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "        # replace the MIN-aggregate with the new agg (one new query for each relation)\n",
    "        i = 1\n",
    "        f_output.write(line)\n",
    "        for new_agg in new_aggs:\n",
    "            result = re.sub(r'MIN\\([^)]*\\)', \"MIN(\" + new_agg + \")\", line)\n",
    "            result = result[:-2] + \"-augA\" + str(i) + '\"' + \"\\n\"\n",
    "            f_output.write(result)\n",
    "            i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
